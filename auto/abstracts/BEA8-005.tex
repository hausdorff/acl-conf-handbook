This paper investigates the use of prompt-based content features for the automated assessment of spontaneous speech in a spoken language proficiency
 assessment. The results show that single highest performing prompt-based
 content feature measures the number of unique lexical types that overlap with
 the listening materials and are not contained in either the reading materials
 or a sample response, with a correlation of r = 0.450 with holistic proficiency
 scores provided by humans. Furthermore, linear regression scoring models that
 combine the proposed prompt-based content features with additional spoken
 language proficiency features are shown to achieve competitive performance with
 scoring models using content features based on pre-scored responses.

