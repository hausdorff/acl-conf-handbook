Many existing approaches for measuring text complexity tend to overestimate the complexity levels of informational texts while simultaneously underestimating
 the complexity levels of literary texts. We present a two-stage estimation
 technique that successfully addresses this problem. At Stage 1, each text is
 classified into one or another of three possible genres: informational,
 literary or mixed. Next, at Stage 2, a complexity score is generated for each
 text by applying one or another of three possible prediction models: one
 optimized for application to informational texts, one optimized for application
 to literary texts, and one optimized for application to mixed texts. Each model
 combines lexical, syntactic and discourse features, as appropriate, to best
 replicate human complexity judgments. We demonstrate that resulting text
 complexity predictions are both unbiased, and highly cor-related with
 classifications provided by experienced educators.

