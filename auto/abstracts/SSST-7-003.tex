In this paper, we empirically investigate the impact of critical configuration parameters in the popular cube pruning algorithm for decoding in hierarchical
 statistical machine translation. Specifically, we study how the choice of the
 k-best generation size affects translation quality and resource requirements
 in hierarchical search. We furthermore examine the influence of two different
 granularities of hypothesis recombination. Our experiments are conducted on the
 large-scale Chinese-to-English and Arabic-to-English NIST translation
 tasks. Besides standard hierarchical grammars, we also explore search with
 restricted recursion depth of hierarchical rules based on shallow-1 grammars.

