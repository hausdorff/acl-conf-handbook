Assessing student understanding by evaluating their free text answers to posed questions is a very important task. However, manually, it is time-consuming and
 computationally, it is difficult. This paper details our shallow NLP approach
 to computationally assessing student free text answers when a reference answer
 is provided. For four out of the five test sets, our system achieved an overall
 accuracy above the median and mean.

