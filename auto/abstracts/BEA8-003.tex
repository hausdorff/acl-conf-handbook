We present the first system developed for automated grading of high school essays written in Swedish.
 The system uses standard text quality indicators and is able to compare
 vocabulary and grammar to large reference corpora of blog posts and newspaper
 articles.
 The system is evaluated on a corpus of 1702 essays, each
 graded independently by the student's own teacher and also in a
 blind re-grading process by another teacher.
 We show that our system's performance is fair, given
 the low agreement between the two human graders, and furthermore show how it
 could improve efficiency in a practical setting where one seeks to identify
 incorrectly graded essays.

