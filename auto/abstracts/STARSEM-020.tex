We combine logical and distributional representations of natural language meaning by transforming distributional similarity judgments into weighted
 inference rules using Markov Logic Networks (MLNs). We show that this framework
 supports both judging sentence similarity and recognizing textual entailment by
 appropriately adapting the MLN implementation of logical connectives. We also
 show that distributional phrase similarity, used as textual inference rules
 created on the fly improves its performance.

