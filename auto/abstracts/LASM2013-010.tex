More and more of the information on the web is dialogic, from Facebook newsfeeds, to forum
 conversations, to comment threads on
 news articles. In contrast to traditional NLP
 resources such as news, highly social dialogue
 is frequent in these genres, making them a
 challenging context for NLP. This paper tests
 a bootstrapping method of training classifiers
 to identify turns in dialogue that are either sarcastic
 or nasty. We explore two methods of
 developing linguistic indicators to be used in a
 first level classifier aimed at maximizing precision
 at the expense of recall. The best performing
 classifier for the first phase achieves
 54\% precision and 38\% recall for sarcastic utterances.
 We then bootstrap from the utterances
 identified as sarcastic by using general
 syntactic patterns to create more general sarcasm
 indicators, improving precision to 62\%
 and recall to 52\%. We apply the same method
 to bootstrapping a classifier for nastiness dialogic
 acts. Our first phase, using crowdsourced
 nasty indicators, achieves 58\% precision
 and 49\% recall, which increases to 75\%
 precision and 62\% recall when we bootstrap
 over phase one with generalized syntactic patterns.

