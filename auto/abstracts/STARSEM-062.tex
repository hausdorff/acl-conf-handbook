In this year's Semantic Textual Similarity evaluation, we explore the contribution of models that provide soft similarity scores across spans of
 multiple words, over the previous year's system. To this end, we explored the
 use of neural probabilistic language models and a TF-IDF weighted variant of
 Explicit Semantic Analysis. The neural language model systems used vector
 representations of individual words, where these vectors were derived by
 training them against the context of words encountered, and thus reflect the
 distributional characteristics of their usage. To generate a similarity score
 between spans, we experimented with using tiled vectors and Restricted
 Boltzmann Machines to identify similar encodings. We find that these soft
 similarity methods generally outperformed our previous year's systems, albeit
 they did not perform as well in the overall rankings. A simple analysis of the
 soft similarity resources over two word phrases is provided, and future areas
 of improvement are described.

