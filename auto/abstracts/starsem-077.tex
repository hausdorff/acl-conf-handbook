Object recognition is a little like translation: a picture (text in a source language) goes in, and a description (text in a target language) comes out. I
 will use this analogy, which has proven fertile, to describe recent progress in
 object recognition.
 
 We have very good methods to spot some objects in images, but extending these
 methods to produce descriptions of images remains very difficult. The
 description might come in the form of a set of words, indicating objects, and
 boxes or regions spanned by the object. This representation is difficult to
 work with, because some objects seem to be much more important than others, and
 because objects interact. An alternative is a sentence or a paragraph
 describing the picture, and recent work indicates how one might generate rich
 structures like this. Furthermore, recent work suggests that it is easier and
 more effective to generate descriptions of images in terms of chunks of meaning
 (''person on a horse'') rather than just objects (''person''; ``horse'').
 
 Finally, if the picture contains objects that are unfamiliar, then we need to
 generate useful descriptions that will make it possible to interact with them,
 even though we don't know what they are.

