In automated speech assessment, adaptation of language models (LMs) to test questions is important to achieve high recognition accuracy. However, for
 large-scale language tests, the ordinary supervised training, which uses an
 expensive and time-consuming manual transcription process, is hard to utilize
 for LM adaptation. In this paper, several LM adaptation methods that require
 either no manual transcription process or just a small amount of transcriptions
 have been evaluated. Our experiments suggest that these LM adaptation methods
 can allow us to obtain considerable recognition accuracy gain with no or low
 human transcription cost.

