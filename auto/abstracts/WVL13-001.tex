We are interested in the task of image annotation using noisy natural text as training data. An image and its caption convey different information, but are
 generated by the same underlying concepts. In this paper, we learn latent
 mixtures of topics that generate image and product descriptions on shopping
 websites by adapting a topic model for multi-lingual data (Minmo et al., 2009).
 We use the trained model to annotate test images without corresponding text.We
 capture visual properties such as color, texture, shape, and orientation by
 computing low-level image features, and measure the contribution of each type
 of visual feature towards the accuracy of the model. Our model significantly
 outperforms both a competitive baseline and a previous topic model-based
 system.

