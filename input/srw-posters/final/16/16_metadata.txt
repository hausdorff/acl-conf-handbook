SubmissionNumber#=%=#16
FinalPaperTitle#=%=#Domain-Independent Captioning of Domain-Specific Images
ShortPaperTitle#=%=#Domain-Independent Captioning of Domain-Specific Images
Author{1}{Lastname}#=%=#Mason
Author{1}{Firstname}#=%=#Rebecca
Author{1}{Email}#=%=#rebecca_mason@brown.edu
Author{1}{Affiliation}#=%=#Brown University
Author{2}{Lastname}#=%=#
Author{2}{Firstname}#=%=#
Author{2}{Email}#=%=#
Author{2}{Affiliation}#=%=#
Author{3}{Lastname}#=%=#
Author{3}{Firstname}#=%=#
Author{3}{Email}#=%=#
Author{3}{Affiliation}#=%=#
Author{4}{Lastname}#=%=#
Author{4}{Firstname}#=%=#
Author{4}{Email}#=%=#
Author{4}{Affiliation}#=%=#
Author{5}{Lastname}#=%=#
Author{5}{Firstname}#=%=#
Author{5}{Email}#=%=#
Author{5}{Affiliation}#=%=#
Author{6}{Lastname}#=%=#
Author{6}{Firstname}#=%=#
Author{6}{Email}#=%=#
Author{6}{Affiliation}#=%=#
Author{7}{Lastname}#=%=#
Author{7}{Firstname}#=%=#
Author{7}{Email}#=%=#
Author{7}{Affiliation}#=%=#
Author{8}{Lastname}#=%=#
Author{8}{Firstname}#=%=#
Author{8}{Email}#=%=#
Author{8}{Affiliation}#=%=#
Author{9}{Lastname}#=%=#
Author{9}{Firstname}#=%=#
Author{9}{Email}#=%=#
Author{9}{Affiliation}#=%=#
Author{10}{Lastname}#=%=#
Author{10}{Firstname}#=%=#
Author{10}{Email}#=%=#
Author{10}{Affiliation}#=%=#
Author{11}{Lastname}#=%=#
Author{11}{Firstname}#=%=#
Author{11}{Email}#=%=#
Author{11}{Affiliation}#=%=#
Author{12}{Lastname}#=%=#
Author{12}{Firstname}#=%=#
Author{12}{Email}#=%=#
Author{12}{Affiliation}#=%=#
Author{13}{Lastname}#=%=#
Author{13}{Firstname}#=%=#
Author{13}{Email}#=%=#
Author{13}{Affiliation}#=%=#
Author{14}{Lastname}#=%=#
Author{14}{Firstname}#=%=#
Author{14}{Email}#=%=#
Author{14}{Affiliation}#=%=#
Author{15}{Lastname}#=%=#
Author{15}{Firstname}#=%=#
Author{15}{Email}#=%=#
Author{15}{Affiliation}#=%=#
NumberOfPages#=%=#8
CopyrightSigned#=%=#Rebecca Mason
JobTitle#==#
Organization#==#Brown University
Department of Computer Science
115 Waterman Street
Providence, RI 02912
Abstract#==#Automatically describing visual content is an extremely difficult task, with
hard AI problems in Computer Vision (CV) and Natural Language Processing (NLP)
at its core. Previous work has relied on supervised visual recognition systems
to determine the content of images. Because these systems require massive
amounts of hand-labeled data for training, the number of visual classes that
can be recognized is typically very small. We
argue that these approaches place unrealistic limits on the kinds of images
that can be captioned, and are unlikely to produce captions which reflect human
interpretations.

We present a framework for image caption generation that does not rely on
visual recognition systems, which we have implemented on a dataset of online
shopping images and product descriptions. We propose future work to improve
this method, and extensions for other domains of images and natural text.
==========