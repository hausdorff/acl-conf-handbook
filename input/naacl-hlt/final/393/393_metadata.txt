SubmissionNumber#=%=#393
FinalPaperTitle#=%=#Large-Scale Discriminative Training for Statistical Machine Translation Using Held-Out Line Search
ShortPaperTitle#=%=#Large-Scale Discriminative Training for SMT
Author{1}{Lastname}#=%=#Flanigan
Author{1}{Firstname}#=%=#Jeffrey
Author{1}{Email}#=%=#jeffflanigan@gmail.com
Author{1}{Affiliation}#=%=#CMU
Author{2}{Lastname}#=%=#Dyer
Author{2}{Firstname}#=%=#Chris
Author{2}{Email}#=%=#cdyer@cs.cmu.edu
Author{2}{Affiliation}#=%=#Carnegie Mellon University
Author{3}{Lastname}#=%=#Carbonell
Author{3}{Firstname}#=%=#Jaime
Author{3}{Email}#=%=#jgc@cs.cmu.edu
Author{3}{Affiliation}#=%=#Carnegie Mellon University
Author{4}{Lastname}#=%=#
Author{4}{Firstname}#=%=#
Author{4}{Email}#=%=#
Author{4}{Affiliation}#=%=#
Author{5}{Lastname}#=%=#
Author{5}{Firstname}#=%=#
Author{5}{Email}#=%=#
Author{5}{Affiliation}#=%=#
Author{6}{Lastname}#=%=#
Author{6}{Firstname}#=%=#
Author{6}{Email}#=%=#
Author{6}{Affiliation}#=%=#
Author{7}{Lastname}#=%=#
Author{7}{Firstname}#=%=#
Author{7}{Email}#=%=#
Author{7}{Affiliation}#=%=#
Author{8}{Lastname}#=%=#
Author{8}{Firstname}#=%=#
Author{8}{Email}#=%=#
Author{8}{Affiliation}#=%=#
Author{9}{Lastname}#=%=#
Author{9}{Firstname}#=%=#
Author{9}{Email}#=%=#
Author{9}{Affiliation}#=%=#
Author{10}{Lastname}#=%=#
Author{10}{Firstname}#=%=#
Author{10}{Email}#=%=#
Author{10}{Affiliation}#=%=#
Author{11}{Lastname}#=%=#
Author{11}{Firstname}#=%=#
Author{11}{Email}#=%=#
Author{11}{Affiliation}#=%=#
Author{12}{Lastname}#=%=#
Author{12}{Firstname}#=%=#
Author{12}{Email}#=%=#
Author{12}{Affiliation}#=%=#
Author{13}{Lastname}#=%=#
Author{13}{Firstname}#=%=#
Author{13}{Email}#=%=#
Author{13}{Affiliation}#=%=#
Author{14}{Lastname}#=%=#
Author{14}{Firstname}#=%=#
Author{14}{Email}#=%=#
Author{14}{Affiliation}#=%=#
Author{15}{Lastname}#=%=#
Author{15}{Firstname}#=%=#
Author{15}{Email}#=%=#
Author{15}{Affiliation}#=%=#
NumberOfPages#=%=#11
CopyrightSigned#=%=#Jeffrey Flanigan
JobTitle#==#
Organization#==#Language Technologies Institute
5000 Forbes Ave
Pittsburgh, PA 15213-3891
Abstract#==#We introduce a new large-scale discriminative learning algorithm for machine
translation that is capable of learning parameters in models with extremely
sparse features. To ensure their reliable estimation and to prevent
overfitting, we use a two-phase learning algorithm. First, the contribution of
individual sparse features is estimated using large amounts of parallel data.
Second, a small development corpus is used to determine the relative
contributions of the sparse features and standard dense features. Not only does
this two-phase learning approach prevent overfitting, the second pass optimizes
corpus-level BLEU of the Viterbi translation of the decoder. We demonstrate
significant improvements using sparse rule indicator features in three
different translation tasks. To our knowledge, this is the first large-scale
discriminative training algorithm capable of showing improvements over the MERT
baseline with only rule indicator features in addition to the standard MERT
features.
==========