SubmissionNumber#=%=#420
FinalPaperTitle#=%=#Massively Parallel Suffix Array Queries and On-Demand Phrase Extraction for Statistical Machine Translation Using GPUs
ShortPaperTitle#=%=#Massively Parallel Suffix Array Queries and On-Demand Phrase Extraction for Statistical Machine Translation Using GPUs
Author{1}{Lastname}#=%=#He
Author{1}{Firstname}#=%=#Hua
Author{1}{Email}#=%=#huah@cs.umd.edu
Author{1}{Affiliation}#=%=#University of Maryland, College Park
Author{2}{Lastname}#=%=#Lin
Author{2}{Firstname}#=%=#Jimmy
Author{2}{Email}#=%=#jimmylin@umd.edu
Author{2}{Affiliation}#=%=#
Author{3}{Lastname}#=%=#Lopez
Author{3}{Firstname}#=%=#Adam
Author{3}{Email}#=%=#alopez@cs.jhu.edu
Author{3}{Affiliation}#=%=#Johns Hopkins University
Author{4}{Lastname}#=%=#
Author{4}{Firstname}#=%=#
Author{4}{Email}#=%=#
Author{4}{Affiliation}#=%=#
Author{5}{Lastname}#=%=#
Author{5}{Firstname}#=%=#
Author{5}{Email}#=%=#
Author{5}{Affiliation}#=%=#
Author{6}{Lastname}#=%=#
Author{6}{Firstname}#=%=#
Author{6}{Email}#=%=#
Author{6}{Affiliation}#=%=#
Author{7}{Lastname}#=%=#
Author{7}{Firstname}#=%=#
Author{7}{Email}#=%=#
Author{7}{Affiliation}#=%=#
Author{8}{Lastname}#=%=#
Author{8}{Firstname}#=%=#
Author{8}{Email}#=%=#
Author{8}{Affiliation}#=%=#
Author{9}{Lastname}#=%=#
Author{9}{Firstname}#=%=#
Author{9}{Email}#=%=#
Author{9}{Affiliation}#=%=#
Author{10}{Lastname}#=%=#
Author{10}{Firstname}#=%=#
Author{10}{Email}#=%=#
Author{10}{Affiliation}#=%=#
Author{11}{Lastname}#=%=#
Author{11}{Firstname}#=%=#
Author{11}{Email}#=%=#
Author{11}{Affiliation}#=%=#
Author{12}{Lastname}#=%=#
Author{12}{Firstname}#=%=#
Author{12}{Email}#=%=#
Author{12}{Affiliation}#=%=#
Author{13}{Lastname}#=%=#
Author{13}{Firstname}#=%=#
Author{13}{Email}#=%=#
Author{13}{Affiliation}#=%=#
Author{14}{Lastname}#=%=#
Author{14}{Firstname}#=%=#
Author{14}{Email}#=%=#
Author{14}{Affiliation}#=%=#
Author{15}{Lastname}#=%=#
Author{15}{Firstname}#=%=#
Author{15}{Email}#=%=#
Author{15}{Affiliation}#=%=#
NumberOfPages#=%=#10
CopyrightSigned#=%=#Hua He
JobTitle#==#
Organization#==#University of Maryland, College Park. 20740, MD, US.
Abstract#==#Translation models in statistical machine translation can be scaled to large
corpora and arbitrarily-long phrases by looking up translations of source
phrases "on the fly" in an indexed parallel corpus using suffix arrays.
However, this can be slow because on-demand extraction of phrase tables is
computationally expensive. We address this problem by developing novel
algorithms for general purpose graphics processing units (GPUs), which enable
suffix array queries for phrase lookup and phrase extraction to be massively
parallelized. Compared to a highly-optimized, state-of-the-art serial CPU-based
implementation, our techniques achieve at least an order of magnitude
improvement in terms of throughput. This work demonstrates the promise of
massively parallel architectures and the potential of GPUs for tackling
computationally-demanding problems in statistical machine translation and
language processing.
==========