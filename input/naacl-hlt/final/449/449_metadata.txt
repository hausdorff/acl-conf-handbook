SubmissionNumber#=%=#449
FinalPaperTitle#=%=#Embracing Ambiguity: A Comparison of Annotation Methodologies for Crowdsourcing Word Sense Labels
ShortPaperTitle#=%=#A Comparison of Annotation Methodologies for Crowdsourcing Word Sense Labels
Author{1}{Lastname}#=%=#Jurgens
Author{1}{Firstname}#=%=#David
Author{1}{Email}#=%=#jurgens@cs.ucla.edu
Author{1}{Affiliation}#=%=#University of California, Los Angeles
Author{2}{Lastname}#=%=#
Author{2}{Firstname}#=%=#
Author{2}{Email}#=%=#
Author{2}{Affiliation}#=%=#
Author{3}{Lastname}#=%=#
Author{3}{Firstname}#=%=#
Author{3}{Email}#=%=#
Author{3}{Affiliation}#=%=#
Author{4}{Lastname}#=%=#
Author{4}{Firstname}#=%=#
Author{4}{Email}#=%=#
Author{4}{Affiliation}#=%=#
Author{5}{Lastname}#=%=#
Author{5}{Firstname}#=%=#
Author{5}{Email}#=%=#
Author{5}{Affiliation}#=%=#
Author{6}{Lastname}#=%=#
Author{6}{Firstname}#=%=#
Author{6}{Email}#=%=#
Author{6}{Affiliation}#=%=#
Author{7}{Lastname}#=%=#
Author{7}{Firstname}#=%=#
Author{7}{Email}#=%=#
Author{7}{Affiliation}#=%=#
Author{8}{Lastname}#=%=#
Author{8}{Firstname}#=%=#
Author{8}{Email}#=%=#
Author{8}{Affiliation}#=%=#
Author{9}{Lastname}#=%=#
Author{9}{Firstname}#=%=#
Author{9}{Email}#=%=#
Author{9}{Affiliation}#=%=#
Author{10}{Lastname}#=%=#
Author{10}{Firstname}#=%=#
Author{10}{Email}#=%=#
Author{10}{Affiliation}#=%=#
Author{11}{Lastname}#=%=#
Author{11}{Firstname}#=%=#
Author{11}{Email}#=%=#
Author{11}{Affiliation}#=%=#
Author{12}{Lastname}#=%=#
Author{12}{Firstname}#=%=#
Author{12}{Email}#=%=#
Author{12}{Affiliation}#=%=#
Author{13}{Lastname}#=%=#
Author{13}{Firstname}#=%=#
Author{13}{Email}#=%=#
Author{13}{Affiliation}#=%=#
Author{14}{Lastname}#=%=#
Author{14}{Firstname}#=%=#
Author{14}{Email}#=%=#
Author{14}{Affiliation}#=%=#
Author{15}{Lastname}#=%=#
Author{15}{Firstname}#=%=#
Author{15}{Email}#=%=#
Author{15}{Affiliation}#=%=#
NumberOfPages#=%=#7
CopyrightSigned#=%=#David Jurgens
JobTitle#==#
Organization#==#University of California, Los Angeles
Los Angeles, California, USA
Abstract#==#Word sense disambiguation aims to identify which meaning of a word is present
in a given usage. Gathering word sense annotations is a laborious and difficult
task.  Several methods have been proposed to gather sense annotations using
large numbers of untrained annotators, with mixed results.  We propose three
new annotation methodologies for gathering word senses where untrained
annotators are allowed to use multiple labels and weight the senses.  Our
findings show that given the appropriate annotation task, untrained workers can
obtain at least as high agreement as annotators in a controlled setting, and in
aggregate generate equally as good of a sense labeling.
==========