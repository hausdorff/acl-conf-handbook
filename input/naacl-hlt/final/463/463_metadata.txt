SubmissionNumber#=%=#463
FinalPaperTitle#=%=#Multi-Metric Optimization Using Ensemble Tuning
ShortPaperTitle#=%=#Multi-Metric Optimization Using Ensemble Tuning
Author{1}{Lastname}#=%=#Sankaran
Author{1}{Firstname}#=%=#Baskaran
Author{1}{Email}#=%=#baskaran@cs.sfu.ca
Author{1}{Affiliation}#=%=#Simon Fraser University
Author{2}{Lastname}#=%=#Sarkar
Author{2}{Firstname}#=%=#Anoop
Author{2}{Email}#=%=#anoop@sfu.ca
Author{2}{Affiliation}#=%=#Simon Fraser University
Author{3}{Lastname}#=%=#Duh
Author{3}{Firstname}#=%=#Kevin
Author{3}{Email}#=%=#kevinduh@is.naist.jp
Author{3}{Affiliation}#=%=#Nara Institute of Science and Technology
Author{4}{Lastname}#=%=#
Author{4}{Firstname}#=%=#
Author{4}{Email}#=%=#
Author{4}{Affiliation}#=%=#
Author{5}{Lastname}#=%=#
Author{5}{Firstname}#=%=#
Author{5}{Email}#=%=#
Author{5}{Affiliation}#=%=#
Author{6}{Lastname}#=%=#
Author{6}{Firstname}#=%=#
Author{6}{Email}#=%=#
Author{6}{Affiliation}#=%=#
Author{7}{Lastname}#=%=#
Author{7}{Firstname}#=%=#
Author{7}{Email}#=%=#
Author{7}{Affiliation}#=%=#
Author{8}{Lastname}#=%=#
Author{8}{Firstname}#=%=#
Author{8}{Email}#=%=#
Author{8}{Affiliation}#=%=#
Author{9}{Lastname}#=%=#
Author{9}{Firstname}#=%=#
Author{9}{Email}#=%=#
Author{9}{Affiliation}#=%=#
Author{10}{Lastname}#=%=#
Author{10}{Firstname}#=%=#
Author{10}{Email}#=%=#
Author{10}{Affiliation}#=%=#
Author{11}{Lastname}#=%=#
Author{11}{Firstname}#=%=#
Author{11}{Email}#=%=#
Author{11}{Affiliation}#=%=#
Author{12}{Lastname}#=%=#
Author{12}{Firstname}#=%=#
Author{12}{Email}#=%=#
Author{12}{Affiliation}#=%=#
Author{13}{Lastname}#=%=#
Author{13}{Firstname}#=%=#
Author{13}{Email}#=%=#
Author{13}{Affiliation}#=%=#
Author{14}{Lastname}#=%=#
Author{14}{Firstname}#=%=#
Author{14}{Email}#=%=#
Author{14}{Affiliation}#=%=#
Author{15}{Lastname}#=%=#
Author{15}{Firstname}#=%=#
Author{15}{Email}#=%=#
Author{15}{Affiliation}#=%=#
NumberOfPages#=%=#11
CopyrightSigned#=%=#Baskaran Sankaran
JobTitle#==#
Organization#==#School of Computing Science
Simon Fraser University
8888 University Dr
Burnaby BC. Canada
Abstract#==#This paper examines tuning for statistical machine translation (SMT) with
respect to multiple evaluation metrics. We propose several novel methods for
tuning towards multiple objectives, including some based on 'ensemble decoding'
methods. Pareto-optimality is a natural way to think about multi-metric
optimization (MMO) and our methods can effectively combine several
Pareto-optimal solutions, obviating the need to choose one. Our best performing
'ensemble tuning' method is a new algorithm for multi-metric optimization that
searches for Pareto-optimal ensemble models. We  study the effectiveness of our
methods through experiments on multiple as well as single reference(s)
datasets. Our experiments show simultaneous gains across several metrics (BLEU,
RIBES), without any significant reduction in other metrics. This contrasts the
traditional tuning where gains are usually limited to a single metric. Our
human evaluation results confirm that in order to produce better MT output,
optimizing multiple metrics is better than optimizing only one.
==========