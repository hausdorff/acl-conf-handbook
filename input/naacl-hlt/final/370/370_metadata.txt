SubmissionNumber#=%=#370
FinalPaperTitle#=%=#Combining multiple information types in Bayesian word segmentation
ShortPaperTitle#=%=#Combining multiple information types in Bayesian word segmentation
Author{1}{Lastname}#=%=#Doyle
Author{1}{Firstname}#=%=#Gabriel
Author{1}{Email}#=%=#gdoyle@ling.ucsd.edu
Author{1}{Affiliation}#=%=#UC San Diego
Author{2}{Lastname}#=%=#Levy
Author{2}{Firstname}#=%=#Roger
Author{2}{Email}#=%=#rlevy@ucsd.edu
Author{2}{Affiliation}#=%=#UC San Diego
Author{3}{Lastname}#=%=#
Author{3}{Firstname}#=%=#
Author{3}{Email}#=%=#
Author{3}{Affiliation}#=%=#
Author{4}{Lastname}#=%=#
Author{4}{Firstname}#=%=#
Author{4}{Email}#=%=#
Author{4}{Affiliation}#=%=#
Author{5}{Lastname}#=%=#
Author{5}{Firstname}#=%=#
Author{5}{Email}#=%=#
Author{5}{Affiliation}#=%=#
Author{6}{Lastname}#=%=#
Author{6}{Firstname}#=%=#
Author{6}{Email}#=%=#
Author{6}{Affiliation}#=%=#
Author{7}{Lastname}#=%=#
Author{7}{Firstname}#=%=#
Author{7}{Email}#=%=#
Author{7}{Affiliation}#=%=#
Author{8}{Lastname}#=%=#
Author{8}{Firstname}#=%=#
Author{8}{Email}#=%=#
Author{8}{Affiliation}#=%=#
Author{9}{Lastname}#=%=#
Author{9}{Firstname}#=%=#
Author{9}{Email}#=%=#
Author{9}{Affiliation}#=%=#
Author{10}{Lastname}#=%=#
Author{10}{Firstname}#=%=#
Author{10}{Email}#=%=#
Author{10}{Affiliation}#=%=#
Author{11}{Lastname}#=%=#
Author{11}{Firstname}#=%=#
Author{11}{Email}#=%=#
Author{11}{Affiliation}#=%=#
Author{12}{Lastname}#=%=#
Author{12}{Firstname}#=%=#
Author{12}{Email}#=%=#
Author{12}{Affiliation}#=%=#
Author{13}{Lastname}#=%=#
Author{13}{Firstname}#=%=#
Author{13}{Email}#=%=#
Author{13}{Affiliation}#=%=#
Author{14}{Lastname}#=%=#
Author{14}{Firstname}#=%=#
Author{14}{Email}#=%=#
Author{14}{Affiliation}#=%=#
Author{15}{Lastname}#=%=#
Author{15}{Firstname}#=%=#
Author{15}{Email}#=%=#
Author{15}{Affiliation}#=%=#
NumberOfPages#=%=#10
CopyrightSigned#=%=#Gabriel Doyle
JobTitle#==#
Organization#==#University of California, San Diego
9500 Gilman Dr. MC 0108
La Jolla, CA 92093
Abstract#==#Humans identify word boundaries in continuous speech by combining multiple
cues; existing state-of-the-art models, though, look at a single cue. We extend
the generative model of Goldwater et al (2006) to segment using syllable
stress as well as phonemic form. Our new model treats identification of word
boundaries and prevalent stress patterns in the language as a joint inference
task.  We show that this model improves segmentation accuracy over purely
segmental input representations, and recovers the dominant stress pattern of
the data.  Additionally, our model retains high performance even without
single-word utterances.  We also demonstrate a discrepancy in the performance
of our model and human infants on an artificial-language task in which stress
cues and transition-probability information are pitted against one another.  We
argue that this discrepancy indicates a bound on rationality in the mechanisms
of human segmentation.
==========