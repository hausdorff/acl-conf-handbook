SubmissionNumber#=%=#62
FinalPaperTitle#=%=#A Systematic Bayesian Treatment of the IBM Alignment Models
ShortPaperTitle#=%=#A Systematic Bayesian Treatment of the IBM Alignment Models
Author{1}{Lastname}#=%=#Gal
Author{1}{Firstname}#=%=#Yarin
Author{1}{Email}#=%=#yarin.gal@cs.ox.ac.uk
Author{1}{Affiliation}#=%=#University of Oxford
Author{2}{Lastname}#=%=#Blunsom
Author{2}{Firstname}#=%=#Phil
Author{2}{Email}#=%=#phil.blunsom@cs.ox.ac.uk
Author{2}{Affiliation}#=%=#University of Oxford
Author{3}{Lastname}#=%=#
Author{3}{Firstname}#=%=#
Author{3}{Email}#=%=#
Author{3}{Affiliation}#=%=#
Author{4}{Lastname}#=%=#
Author{4}{Firstname}#=%=#
Author{4}{Email}#=%=#
Author{4}{Affiliation}#=%=#
Author{5}{Lastname}#=%=#
Author{5}{Firstname}#=%=#
Author{5}{Email}#=%=#
Author{5}{Affiliation}#=%=#
Author{6}{Lastname}#=%=#
Author{6}{Firstname}#=%=#
Author{6}{Email}#=%=#
Author{6}{Affiliation}#=%=#
Author{7}{Lastname}#=%=#
Author{7}{Firstname}#=%=#
Author{7}{Email}#=%=#
Author{7}{Affiliation}#=%=#
Author{8}{Lastname}#=%=#
Author{8}{Firstname}#=%=#
Author{8}{Email}#=%=#
Author{8}{Affiliation}#=%=#
Author{9}{Lastname}#=%=#
Author{9}{Firstname}#=%=#
Author{9}{Email}#=%=#
Author{9}{Affiliation}#=%=#
Author{10}{Lastname}#=%=#
Author{10}{Firstname}#=%=#
Author{10}{Email}#=%=#
Author{10}{Affiliation}#=%=#
Author{11}{Lastname}#=%=#
Author{11}{Firstname}#=%=#
Author{11}{Email}#=%=#
Author{11}{Affiliation}#=%=#
Author{12}{Lastname}#=%=#
Author{12}{Firstname}#=%=#
Author{12}{Email}#=%=#
Author{12}{Affiliation}#=%=#
Author{13}{Lastname}#=%=#
Author{13}{Firstname}#=%=#
Author{13}{Email}#=%=#
Author{13}{Affiliation}#=%=#
Author{14}{Lastname}#=%=#
Author{14}{Firstname}#=%=#
Author{14}{Email}#=%=#
Author{14}{Affiliation}#=%=#
Author{15}{Lastname}#=%=#
Author{15}{Firstname}#=%=#
Author{15}{Email}#=%=#
Author{15}{Affiliation}#=%=#
NumberOfPages#=%=#9
CopyrightSigned#=%=#Yarin
JobTitle#==#
Organization#==#Yarin Gal
Department of Engineering
University of Cambridge
Cambridge, CB2 1PZ, United Kingdom
yg279@cam.ac.uk
Abstract#==#The dominant yet ageing IBM and HMM
word alignment models underpin most
popular Statistical Machine Translation
implementations in use today. Though
beset by the limitations of implausible
independence assumptions, intractable
optimisation problems, and an excess of
tunable parameters, these models provide
a scalable and reliable starting point for
inducing translation systems. In this paper we
build upon this venerable base by recasting
these models in the non-parametric Bayesian
framework. By replacing the categorical
distributions at their core with hierarchical
Pitman-Yor processes, and through the use
of collapsed Gibbs sampling, we provide a
more flexible formulation and sidestep the
original heuristic optimisation techniques.
The resulting models are highly extendible,
naturally permitting the introduction of
phrasal dependencies. We present extensive
experimental results showing improvements
in both AER and BLEU when benchmarked
against Giza++, including significant
improvements over IBM model 4.
==========