SubmissionNumber#=%=#68
FinalPaperTitle#=%=#IBM\_EG-CORE: Comparing multiple Lexical and NE matching features in measuring Semantic Textual similarity
ShortPaperTitle#=%=#IBM\_EG-CORE: Comparing multiple Lexical and NE matching features in measuring Semantic Textual similarity
Author{1}{Lastname}#=%=#Noeman
Author{1}{Firstname}#=%=#Sara
Author{1}{Email}#=%=#noemans@eg.ibm.com
Author{1}{Affiliation}#=%=#IBM Cairo Technology Development Center
Author{2}{Lastname}#=%=#
Author{2}{Firstname}#=%=#
Author{2}{Email}#=%=#
Author{2}{Affiliation}#=%=#
Author{3}{Lastname}#=%=#
Author{3}{Firstname}#=%=#
Author{3}{Email}#=%=#
Author{3}{Affiliation}#=%=#
Author{4}{Lastname}#=%=#
Author{4}{Firstname}#=%=#
Author{4}{Email}#=%=#
Author{4}{Affiliation}#=%=#
Author{5}{Lastname}#=%=#
Author{5}{Firstname}#=%=#
Author{5}{Email}#=%=#
Author{5}{Affiliation}#=%=#
Author{6}{Lastname}#=%=#
Author{6}{Firstname}#=%=#
Author{6}{Email}#=%=#
Author{6}{Affiliation}#=%=#
Author{7}{Lastname}#=%=#
Author{7}{Firstname}#=%=#
Author{7}{Email}#=%=#
Author{7}{Affiliation}#=%=#
Author{8}{Lastname}#=%=#
Author{8}{Firstname}#=%=#
Author{8}{Email}#=%=#
Author{8}{Affiliation}#=%=#
Author{9}{Lastname}#=%=#
Author{9}{Firstname}#=%=#
Author{9}{Email}#=%=#
Author{9}{Affiliation}#=%=#
Author{10}{Lastname}#=%=#
Author{10}{Firstname}#=%=#
Author{10}{Email}#=%=#
Author{10}{Affiliation}#=%=#
Author{11}{Lastname}#=%=#
Author{11}{Firstname}#=%=#
Author{11}{Email}#=%=#
Author{11}{Affiliation}#=%=#
Author{12}{Lastname}#=%=#
Author{12}{Firstname}#=%=#
Author{12}{Email}#=%=#
Author{12}{Affiliation}#=%=#
Author{13}{Lastname}#=%=#
Author{13}{Firstname}#=%=#
Author{13}{Email}#=%=#
Author{13}{Affiliation}#=%=#
Author{14}{Lastname}#=%=#
Author{14}{Firstname}#=%=#
Author{14}{Email}#=%=#
Author{14}{Affiliation}#=%=#
Author{15}{Lastname}#=%=#
Author{15}{Firstname}#=%=#
Author{15}{Email}#=%=#
Author{15}{Affiliation}#=%=#
NumberOfPages#=%=#7
CopyrightSigned#=%=#Sara Noeman
JobTitle#==#
Organization#==#Sara Noeman
IBM Cairo Technology and Development Center
Giza, Egypt
P.O. Box 166 Al-Ahram
Abstract#==#We present the systems we participated with in the Semantic Textual Similarity
task at *SEM 2013. The Semantic Textual Similarity Core task  (STS) computes
the degree of semantic equivalence between two sentences where the participant
systems will be compared to the manual scores, which range from 5 (semantic
equivalence) to 0 (no relation). We combined multiple text similarity measures
of varying complexity. The experiments illustrate the different effect of four
feature types including direct lexical matching, idf-weighted lexical matching,
modified BLEU N-gram matching and named entities matching. Our team submitted
three runs during the task evaluation period and they ranked number 11, 15 and
19 among the 90 participating systems according to the official Mean Pearson
correlation metric for the task. We also report an unofficial run with mean
Pearson correlation of 0.59221 on STS2013 test dataset, ranking as the 3rd best
system among the 90 participating systems.
==========