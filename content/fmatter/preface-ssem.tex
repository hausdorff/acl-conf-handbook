%\section*{Preface: *SEM 2012}\vspace{2em}
\begin{center}
  {\Large \bf Introduction to *SEM 2013}
\end{center}


Building on the momentum generated by the spectacular success of the
Joint Conference on Lexical and Computational Semantics (*SEM) in 2012,
bringing together the ACL SIGLEX and ACL SIGSEM communities, we are
delighted to bring to you the second edition of the conference, as a
top-tier showcase of the latest research in computational semantics. We
accepted 14 papers (11 long and 3 short) for publication at the
conference, out of a possible 45 submissions (a 31\% acceptance
rate). This is on par with some of the most competitive conferences in
computational linguistics, and we are confident will set the stage for a
scintillating conference.  

This year, we started a tradition that we intend to maintain in all
future iterations of the conference in integrating a shared task into
the conference. The shared task was selected by an independent committee
comprising members from SIGLEX and SIGSEM, based on an open call for
proposals, and revolved around Semantic Textual Similarity (STS). The
task turned out to be a huge success with 34 teams participating,
submitting a total of 103 system runs.

*SEM 2013 features a number of highlight events:
%
\begin{description}
\item[] \textbf{Day One, June 13th:}\\[-2ex]
  \begin{itemize}
  \item A timely and impressive panel on \textit{Towards Deep
      Natural Language Understanding}, featuring the following
    panelists:

    \begin{itemize}
    \item {Kevin Knight} (USC/Information Sciences Institute)
    \item {Chris Manning} (Stanford University)
    \item {Martha Palmer} (University of Colorado at Boulder)
    \item {Owen Rambow} (Columbia University)
    \item {Dan Roth} (University of Illinois at Urbana-Champaign)
    \end{itemize}

  \item A Reception and Shared Task Poster Session in the evening,
    thanks to the generous sponsorship of the DARPA Deft program. \\
  \end{itemize}
\item[] \textbf{Day Two, June 14th:}\\[-2ex]
    \begin{itemize}
    \item In the morning, a keynote address by David Forsyth
      from the Computer Science Department at the University of Illinois
      at Urbana Champagne on issues of Vision and Language. It promises
      to be an
      extremely stimulating speech, and is not to be missed.


    \item In the early afternoon, a panel on the relation between and
      future of *SEM, the *SEM Shared Task, SemEval and other events on
      computational semantics. In this panel, we will attempt to clarify
      and explain as well as devise plans for these different entities.

    \item Finally, at the end of the day, an award ceremony for the Best Long Paper and Best Short Paper. 
    \end{itemize}
\end{description}
%
As always, *SEM 2013 would not have been possible without the
considerable efforts of our area chairs and an impressive assortment of reviewers, drawn from the
ranks of SIGLEX and SIGSEM, and the computational semantics community at
large. We would also like to acknowledge the generous support for the STS Task from the DARPA Deft Program. 

We hope you enjoy *SEM 2013, and look forward to engaging with all of you, \\[2ex]



\noindent{Mona Diab} (The George Washington University, General Chair)\\
Timothy Baldwin (The University of Mebourne, Program Committee Co-Chair)\\
Marco Baroni (University of Trento, Program Committee Co-Chair)\\

\index{Diab, Mona}
\index{Baldwin, Timothy}
\index{Baroni, Marco}

\newpage

\begin{center}
  {\Large \bf Introduction to SemEval}
\end{center}


The Semantic Evaluation (SemEval) series of workshops focus on the evaluation and comparison of systems that can analyse diverse semantic phenomena in text with the aim of extending the current state-of-the-art in semantic analysis and creating high quality annotated datasets in a range of increasingly challenging problems in natural language semantics.  SemEval provides an exciting forum for researchers to propose challenging research problems in semantics and to build systems/techniques to address such research problems.

SemEval-2013 is the seventh workshop in the series.  The first three workshops, SensEval-1 (1998), SensEval-2 (2001), and SensEval-3 (2004), were focused on word sense disambiguation, each time growing in the number of languages offered in the tasks and in the number of participating teams. In 2007 the workshop was renamed SemEval and in the next three workshops SemEval-2007, SemEval-2010 and SemEval-2012 the nature of the tasks evolved to include semantic analysis tasks outside of word sense disambiguation.  Starting in 2012 SemEval turned into a yearly event associated with *SEM.

This volume contains papers accepted for presentation at the SemEval-2013 International Workshop on Semantic Evaluation Exercises. SemEval-2013 is co-organized with the *SEM-2013 The Second Joint Conference on Lexical and Computational Semantics and co-located with The 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL HLT).

SemEval-2013 included the following 12 tasks for evaluation:

\begin{itemize}

\item TempEval-3 Temporal Annotation

\item Sentiment Analysis in Twitter

\item Spatial Role Labeling

\item Free Paraphrases of Noun Compounds

\item Evaluating Phrasal Semantics

\item The Joint Student Response Analysis and 8th Recognizing Textual Entailment Challenge

\item Cross-lingual Textual Entailment for Content Synchronization

\item Extraction of Drug-Drug Interactions from BioMedical Texts

\item Cross-lingual Word Sense Disambiguation

\item Evaluating Word Sense Induction \& Disambiguation within An End-User Application

\item Multilingual Word Sense Disambiguation

\item Word Sense Induction for Graded and Non-Graded Senses

\end{itemize}

About 100 teams submitted more than 300 systems for the 12 tasks of SemEval-2013.  This volume contains both Task Description papers that describe each of the above tasks and System Description papers that describe the systems that participated in the above tasks. A total of 12 task description papers and 101 system description papers are included in this volume.

We are indebted to all program committee members for their high quality, elaborate and thoughtful reviews. The papers in this proceedings have surely benefited from this feedback.  We are grateful to *SEM 2013 and NAACL-HLT 2013 conference organizers for local organization and the forum. We most gratefully acknowledge the support of our sponsors, the ACL Special Interest Group on the Lexicon (SIGLEX) and the ACL Special Interest Group on Computational Semantics (SIGSEM).

Welcome to SemEval-2013!

Suresh Manandhar and Deniz Yuret
\index{Manandhar, Suresh}
\index{Yuret, Deniz}

\cleardoublepage

